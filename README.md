[合集 \- FFmpeg开发实战(59\)](https://github.com)[1\.FFmpeg开发笔记（一）搭建Linux系统的开发环境2023\-04\-16](https://github.com/aqi00/p/17323833.html)[2\.FFmpeg开发笔记（二）搭建Windows系统的开发环境2023\-04\-29](https://github.com/aqi00/p/17363751.html)[3\.FFmpeg开发笔记（三）FFmpeg的可执行程序介绍03\-09](https://github.com/aqi00/p/18062895)[4\.FFmpeg开发笔记（四）FFmpeg的动态链接库介绍03\-10](https://github.com/aqi00/p/18062898)[5\.FFmpeg开发笔记（五）更新MSYS的密钥环03\-16](https://github.com/aqi00/p/18062901)[6\.FFmpeg开发笔记（六）如何访问Github下载FFmpeg源码03\-17](https://github.com/aqi00/p/18062902)[7\.FFmpeg开发笔记（九）Linux交叉编译Android的x265库03\-30](https://github.com/aqi00/p/18078413)[8\.FFmpeg开发笔记（十）Linux环境给FFmpeg集成vorbis和amr03\-31](https://github.com/aqi00/p/18078414)[9\.FFmpeg开发笔记（十一）Windows环境给FFmpeg集成vorbis和amr04\-05](https://github.com/aqi00/p/18078415)[10\.FFmpeg开发笔记（七）欧拉系统编译安装FFmpeg03\-23](https://github.com/aqi00/p/18062905)[11\.FFmpeg开发笔记（八）Linux交叉编译Android的FFmpeg库03\-24](https://github.com/aqi00/p/18062906)[12\.FFmpeg开发笔记（十二）Linux环境给FFmpeg集成libopus和libvpx04\-06](https://github.com/aqi00/p/18105739)[13\.FFmpeg开发笔记（十三）Windows环境给FFmpeg集成libopus和libvpx04\-13](https://github.com/aqi00/p/18105744)[14\.FFmpeg开发笔记（十四）FFmpeg音频重采样的缓存04\-14](https://github.com/aqi00/p/18105749)[15\.FFmpeg开发笔记（十五）详解MediaMTX的推拉流04\-20](https://github.com/aqi00/p/18105753)[16\.FFmpeg开发笔记（十六）Linux交叉编译Android的OpenSSL库04\-21](https://github.com/aqi00/p/18132687)[17\.FFmpeg开发笔记（十七）Windows环境给FFmpeg集成字幕库libass04\-27](https://github.com/aqi00/p/18132702)[18\.FFmpeg开发笔记（十八）FFmpeg兼容各种音频格式的播放05\-04](https://github.com/aqi00/p/18132704)[19\.FFmpeg开发笔记（十九）FFmpeg开启两个线程分别解码音视频05\-05](https://github.com/aqi00/p/18161897)[20\.FFmpeg开发笔记（二十）Linux环境给FFmpeg集成AVS3解码器05\-12](https://github.com/aqi00/p/18161901)[21\.FFmpeg开发笔记（二十一）Windows环境给FFmpeg集成AVS3解码器05\-18](https://github.com/aqi00/p/18161908)[22\.FFmpeg开发笔记（二十二）FFmpeg中SAR与DAR的显示宽高比05\-19](https://github.com/aqi00/p/18161912)[23\.FFmpeg开发笔记（二十三）使用OBS Studio开启RTMP直播推流05\-26](https://github.com/aqi00/p/18199486)[24\.FFmpeg开发笔记（二十四）Linux环境给FFmpeg集成AV1的编解码器05\-27](https://github.com/aqi00/p/18199491)[25\.FFmpeg开发笔记（二十五）Linux环境给FFmpeg集成libwebp06\-01](https://github.com/aqi00/p/18199496)[26\.FFmpeg开发笔记（二十六）Linux环境安装ZLMediaKit实现视频推流06\-02](https://github.com/aqi00/p/18199499)[27\.FFmpeg开发笔记（二十七）解决APP无法访问ZLMediaKit的直播链接问题06\-08](https://github.com/aqi00/p/18199503)[28\.FFmpeg开发笔记（二十八）Linux环境给FFmpeg集成libxvid06\-09](https://github.com/aqi00/p/18199506)[29\.FFmpeg开发笔记（二十九）Windows环境给FFmpeg集成libxvid06\-15](https://github.com/aqi00/p/18239870)[30\.FFmpeg开发笔记（三十）解析H.264码流中的SPS帧和PPS帧06\-16](https://github.com/aqi00/p/18239876):[飞数机场](https://ze16.com)[31\.FFmpeg开发笔记（三十一）使用RTMP Streamer开启APP直播推流06\-22](https://github.com/aqi00/p/18239879)[32\.FFmpeg开发笔记（三十二）利用RTMP协议构建电脑与手机的直播Demo06\-23](https://github.com/aqi00/p/18239882)[33\.FFmpeg开发笔记（三十三）分析ZLMediaKit对H.264流的插帧操作06\-29](https://github.com/aqi00/p/18240179)[34\.FFmpeg开发笔记（三十四）Linux环境给FFmpeg集成libsrt和librist06\-30](https://github.com/aqi00/p/18240185)[35\.FFmpeg开发笔记（三十五）Windows环境给FFmpeg集成libsrt07\-06](https://github.com/aqi00/p/18240192)[36\.FFmpeg开发笔记（三十六）Linux环境安装SRS实现视频直播推流07\-07](https://github.com/aqi00/p/18240199)[37\.FFmpeg开发笔记全目录（FFmpeg开发实战详解，含直播系统的搭建过程）06\-17](https://github.com/aqi00/p/18250735)[38\.FFmpeg开发笔记（三十七）分析SRS对HLS协议里TS包的插帧操作07\-13](https://github.com/aqi00/p/18288623)[39\.FFmpeg开发笔记（三十八）APP如何访问SRS推流的RTMP直播地址07\-14](https://github.com/aqi00/p/18288628)[40\.FFmpeg开发笔记（三十九）给Visual Studio的C\+\+工程集成FFmpeg07\-20](https://github.com/aqi00/p/18288635)[41\.FFmpeg开发笔记（四十）Nginx集成rtmp模块实现RTMP推拉流07\-21](https://github.com/aqi00/p/18288637)[42\.FFmpeg开发笔记（四十一）结合OBS与MediaMTX实现SRT直播推流07\-27](https://github.com/aqi00/p/18288640)[43\.FFmpeg开发笔记（四十二）使用ZLMediaKit开启SRT视频直播服务07\-28](https://github.com/aqi00/p/18288642)[44\.FFmpeg开发笔记（四十三）使用SRS开启SRT协议的视频直播服务08\-03](https://github.com/aqi00/p/18288645)[45\.FFmpeg开发笔记（四十四）毕业设计可做的几个拉满颜值的音视频APP08\-04](https://github.com/aqi00/p/18328118)[46\.FFmpeg开发笔记（四十五）使用SRT Streamer开启APP直播推流08\-10](https://github.com/aqi00/p/18328119)[47\.FFmpeg开发笔记（四十六）利用SRT协议构建手机APP的直播Demo08\-11](https://github.com/aqi00/p/18328121)[48\.FFmpeg开发笔记（四十七）寒冬下安卓程序员的几个技术转型发展方向08\-17](https://github.com/aqi00/p/18328122)[49\.FFmpeg开发笔记（四十八）从0开始搭建直播系统的开源软件架构08\-18](https://github.com/aqi00/p/18328123)[50\.FFmpeg开发笔记（四十九）助您在毕业设计中脱颖而出的几个流行APP08\-31](https://github.com/aqi00/p/18328125)[51\.FFmpeg开发笔记（五十）聊聊几种流媒体传输技术的前世今生09\-01](https://github.com/aqi00/p/18390366)[52\.FFmpeg开发笔记（五十一）适合学习研究的几个音视频开源框架09\-07](https://github.com/aqi00/p/18390371)[53\.FFmpeg开发笔记（五十二）移动端的国产视频播放器GSYVideoPlayer09\-08](https://github.com/aqi00/p/18390374)[54\.FFmpeg开发笔记（五十三）移动端的国产直播录制工具EasyPusher09\-21](https://github.com/aqi00/p/18390381)[55\.FFmpeg开发笔记（五十四）使用EasyPusher实现移动端的RTSP直播09\-22](https://github.com/aqi00/p/18390389)[56\.FFmpeg开发笔记（五十五）寒冬里的安卓程序员可进阶修炼的几种姿势10\-12](https://github.com/aqi00/p/18450136)[57\.FFmpeg开发笔记（五十六）使用Media3的Exoplayer播放网络视频10\-13](https://github.com/aqi00/p/18450140)[58\.FFmpeg开发笔记（五十七）使用Media3的Transformer加工视频文件10\-16](https://github.com/aqi00/p/18450142)59\.FFmpeg开发笔记（五十八）把32位采样的MP3转换为16位的PCM音频10\-19收起
​《FFmpeg开发实战：从零基础到短视频上线》一书的“5\.1\.2  把音频流保存为PCM文件”介绍了如何把媒体文件中的音频流转存为原始的PCM音频，在样例代码的转存过程中，解码后的PCM数据未经任何加工处理，就直接保存到二进制文件。也就是说，原音频的采样频率是多少，PCM文件的采样频率也是多少；原音频的声道数量是多少，PCM文件的声道数量也是多少；原音频的采样位数是多少，PCM文件的采样位数也是多少。
 原汁原味保存的PCM文件本来也没什么问题，可是在实际应用中，有的业务场景需要特定规格的PCM音频。比如某厂家的语音识别引擎，要求只能输入16位的PCM数据，然而标准的MP3音频都采用32位采样，如此一来，得想办法把32位的MP3音频转换为16位的PCM音频才行。
考虑到使用FFmpeg的命令行转换比较方便，于是在控制台执行下面的ffmpeg格式转换指令，在转换采样频率和声道数量的同时一起转换采样位数。




```
ffmpeg -i night.mp3 -ar 16000 -ac 1 -acodec pcm_s16le night.pcm
```


谁知控制台输出以下的报错信息“pcm\_s16le codec not supported”，意思是不支持16位的PCM编码器。




```
pcm_s16le codec not supported
```


咦，FFmpeg怎么会不支持这么基本的PCM编码器呢？继续执行下面的编码器查看命令：




```
ffmpeg -encoders | grep pcm
```


发现输出的查询结果赫然出现下面的pcm\_s16le信息，说明FFmpeg默认已经支持该编码器。




```
A....D pcm_s16le            PCM signed 16-bit little-endian
```


那么为啥ffmpeg命令行无法正常转换PCM音频的采样位数呢？
搜了一圈发现没有使用ffmpeg成功转换采样位数的案例，只好先把原音频转换为32位采样的PCM文件，转换命令如下所示：




```
ffmpeg -i night.mp3 -ar 16000 -ac 1 -acodec pcm_f32le -f f32le night.pcm
```


接下来另外编写转换音频采样位数的代码convertpcm.c，代码内容如下所示：




```
#include 
#include 
#include 

int pcm32_to_pcm16(const char *filename)
{  
    FILE *fp =  fopen(filename, "rb");
    FILE *fp1 = fopen("output_16.pcm", "wb");
    unsigned char *sample = (unsigned char*)calloc(1, 4+1);
    while(!feof(fp))
    {
        fread(sample, 4, 1, fp);
        sample[4] = '\0';
        float *sample32 = (float*)sample;
        short sample16 = (short)floor( (*sample32) * 32767 );
        fwrite(&sample16, 2, 1, fp1);
    }
    free(sample);
    fclose(fp);
    fclose(fp1);
    return 0;  
}

int main(int argc, char **argv) {
    const char *src_name = "night.pcm";
    if (argc > 1) {
        src_name = argv[1];
    }
    pcm32_to_pcm16(src_name);
}
```


保存代码，然后执行下面的编译命令。




```
gcc convertpcm.c -o convertpcm 
```


编译完成，再执行下面的采样位数转换命令。




```
./convertpcm night.pcm
```


现在生成的output\_16\.pcm就是16位采样的PCM文件，可以用作语音识别了。


更多详细的FFmpeg开发知识参见[《FFmpeg开发实战：从零基础到短视频上线》](https://item.jd.com/14020415.html "《FFmpeg开发实战：从零基础到短视频上线》")一书。


